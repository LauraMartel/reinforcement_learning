{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b671ca8-5462-495e-a4a5-383115d0e9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in /home/lauradata/.pyenv/versions/3.8.12/envs/reinforcement_learning/lib/python3.8/site-packages (2.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b362f4c-dd5c-48aa-a217-0d7cb54fc726",
   "metadata": {},
   "outputs": [],
   "source": [
    " # https://github.com/bvpsk/Reinforcement-learning/blob/51a33c09c64e55509b5d5084d005a6cd0299be86/Q-Learning/simple_game.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d7c0819-f5d7-47e1-bb18-cb8c8fa17abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1319999999999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "from time import time,sleep\n",
    "from random import randint as r\n",
    "import random\n",
    "import pickle\n",
    "n = 7\n",
    "scrx = n*100\n",
    "scry = n*100\n",
    "background = (51,51,51)\n",
    "screen = pygame.display.set_mode((scrx,scry))\n",
    "# colors = [(51,51,51),(51,51,51),(255,0,0),(51,51,51),(255,0,0),(255,255,0),(51,51,51),(255,0,0),(51,51,51),(255,0,0),(255,255,0),(51,51,51)\n",
    "# ,(51,51,51),(0,255,0),(51,51,51),(255,255,0)]\n",
    "# reward = np.array([[-1,-5,-1,-1],[-1,1,-5,10],[-5,-1,1,-1],[-1,-5,-1,1]])\n",
    "# terminals = [1,6,7,8,13]\n",
    "colors = [(51,51,51),(51,51,51),(51,51,51),(51,51,51),(51,51,51),(255,0,0),(255,0,0),(51,51,51),(51,51,51),(51,51,51),(0,255,0),(51,51,51)\n",
    ",(51,51,51),(51,51,51),(51,51,51),(51,51,51)]\n",
    "reward = np.array([[0,0,0,0],[0,-1,0,0],[0,-1,1,0],[0,0,0,0]])\n",
    "terminals = [5,9,10]\n",
    "colors = [(51,51,51) for i in range(n**2)]\n",
    "reward = np.zeros((n,n))\n",
    "goals = 1\n",
    "terminals = []\n",
    "penalities = 10\n",
    "while penalities != 0:\n",
    "    i = r(0,n-1)\n",
    "    j = r(0,n-1)\n",
    "    if reward[i,j] == 0 and [i,j] != [0,0] and [i,j] != [n-1,n-1]:\n",
    "        reward[i,j] = -1\n",
    "        penalities-=1\n",
    "        colors[n*i+j] = (255,0,0)\n",
    "        terminals.append(n*i+j)\n",
    "reward[n-1,n-1] = 1\n",
    "colors[n**2 - 1] = (0,255,0)\n",
    "terminals.append(n**2 - 1)\n",
    "# while goals != 0:\n",
    "#     i = r(0,3)\n",
    "#     j = r(0,3)\n",
    "#     if reward[i,j] == 0 and [i,j] != [0,0]:\n",
    "#         reward[i,j] = 1\n",
    "#         goals-=1\n",
    "#         colors[n*i+j] = (0,255,0)\n",
    "#         terminals.append(n*i+j)\n",
    "\n",
    "# f = open(\"Q.txt\",\"r\")\n",
    "Q = np.zeros((n**2,4))\n",
    "# Q = pickle.loads(f.read())\n",
    "# f.close()\n",
    "actions = {\"up\": 0,\"down\" : 1,\"left\" : 2,\"right\" : 3}\n",
    "# states = {0 : 0, 10 : 1, -1 : 2, 1 : 3} #nothing,reward,penality,goal\n",
    "states = {}\n",
    "k = 0\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        states[(i,j)] = k\n",
    "        k+=1\n",
    "alpha = 0.01\n",
    "gamma = 0.9\n",
    "current_pos = [0,0]\n",
    "epsilon = 0.25\n",
    "def layout():\n",
    "    c = 0\n",
    "    for i in range(0,scrx,100):\n",
    "        for j in range(0,scry,100):\n",
    "            pygame.draw.rect(screen,(255,255,255),(j,i,j+100,i+100),0)\n",
    "            pygame.draw.rect(screen,colors[c],(j+3,i+3,j+95,i+95),0)\n",
    "            c+=1\n",
    "def select_action(current_state):\n",
    "    global current_pos,epsilon\n",
    "    possible_actions = []\n",
    "    if np.random.uniform() <= epsilon:\n",
    "        if current_pos[1] != 0:\n",
    "            possible_actions.append(\"left\")\n",
    "        if current_pos[1] != n-1:\n",
    "            possible_actions.append(\"right\")\n",
    "        if current_pos[0] != 0:\n",
    "            possible_actions.append(\"up\")\n",
    "        if current_pos[0] != n-1:\n",
    "            possible_actions.append(\"down\")\n",
    "        action = actions[possible_actions[r(0,len(possible_actions) - 1)]]\n",
    "    else:\n",
    "        m = np.min(Q[current_state])\n",
    "        if current_pos[0] != 0:\n",
    "            possible_actions.append(Q[current_state,0])\n",
    "        else:\n",
    "            possible_actions.append(m - 100)\n",
    "        if current_pos[0] != n-1:\n",
    "            possible_actions.append(Q[current_state,1])\n",
    "        else:\n",
    "            possible_actions.append(m - 100)\n",
    "        if current_pos[1] != 0:\n",
    "            possible_actions.append(Q[current_state,2])\n",
    "        else:\n",
    "            possible_actions.append(m - 100)\n",
    "        if current_pos[1] != n-1:\n",
    "            possible_actions.append(Q[current_state,3])\n",
    "        else:\n",
    "            possible_actions.append(m - 100)\n",
    "        # action = np.argmax(possible_actions)\n",
    "        action = random.choice([i for i,a in enumerate(possible_actions) if a == max(possible_actions)])\n",
    "        return action\n",
    "def episode():\n",
    "    global current_pos,epsilon\n",
    "    current_state = states[(current_pos[0],current_pos[1])]\n",
    "    action = select_action(current_state)\n",
    "    if action == 0:\n",
    "        current_pos[0] -= 1\n",
    "    elif action == 1:\n",
    "        current_pos[0] += 1\n",
    "    elif action == 2:\n",
    "        current_pos[1] -= 1\n",
    "    elif action == 3:\n",
    "        current_pos[1] += 1\n",
    "    new_state = states[(current_pos[0],current_pos[1])]\n",
    "    if new_state not in terminals:\n",
    "        Q[current_state,action] += alpha*(reward[current_pos[0],current_pos[1]] + gamma*(np.max(Q[new_state])) - Q[current_state,action])\n",
    "    else:\n",
    "        Q[current_state,action] += alpha*(reward[current_pos[0],current_pos[1]] - Q[current_state,action])\n",
    "        current_pos = [0,0]\n",
    "        epsilon -= 1e-3\n",
    "\n",
    "\n",
    "run = True\n",
    "for i in range(000):\n",
    "    episode()\n",
    "current_pos = [0,0]\n",
    "while run:\n",
    "    # sleep(0.3)\n",
    "    screen.fill(background)\n",
    "    layout()\n",
    "    pygame.draw.circle(screen,(25,129,230),(current_pos[1]*100 + 50,current_pos[0]*100 + 50),30,0)\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            run = False\n",
    "    pygame.display.flip()\n",
    "    episode()\n",
    "\n",
    "pygame.quit()\n",
    "print(epsilon)\n",
    "# f = open(\"Q.txt\",\"w\")\n",
    "# f.write(pickle.dumps(Q))\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98934e54-3e16-4bd8-ba7f-0cbdc42b3973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 (default, Jul  8 2022, 13:32:06) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "eefa8d817d47bfeb795d6b1a1f08ab598be58cbefd848c033aca6f45f46d3255"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
