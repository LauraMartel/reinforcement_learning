{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea81e45f-e3eb-45d5-9bbe-9c3d50df77ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in /home/lauradata/.pyenv/versions/3.8.12/envs/reinforcement_learning/lib/python3.8/site-packages (2.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a92f3f24-7dd3-45e8-bcc0-92f3b79347fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.16, Python 3.8.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "from time import time,sleep\n",
    "from random import randint as r\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb87a654-ade4-439a-84e6-5568e54b6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    " ### Description\n",
    "# There are three designated locations in the grid world indicated by R(ed),\n",
    "# G(reen), and B(lue). When the episode starts, the START is \n",
    "# at a random square and the EXIT is at a random square. The START path\n",
    "# must pass by the TREASURE, from the TREASURE, the path leads to the EXIT. at the EXIT the episode ends. There are 4 obstacles called WALL.\n",
    "# Map:\n",
    "# S(tart), P(ath), T(reasure), W(all), E(xit)\n",
    "# \"4x4\":[\"SPPW\",\n",
    "#        \"PWPP\",\n",
    "#        \"PTPW\",\n",
    "#        \"PWPE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4febc4-ec43-4fbf-ad4b-4ab86d03143f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "scrx = n*100\n",
    "scry = n*100\n",
    "background = (51,51,51)\n",
    "screen = pygame.display.set_mode((scrx,scry))\n",
    "colors = [(51,51,51) for i in range(n**2)]\n",
    "reward = np.zeros((n,n))\n",
    "terminals = []\n",
    "penalities = 4\n",
    "\n",
    "# learning rate\n",
    "alpha = 0.01\n",
    "\n",
    "# weight measure of how important do we find future actions vs current action or future reward over current reward. values between 0 and 1\n",
    "gamma = 0.9\n",
    "\n",
    "current_pos = [0,0]\n",
    "\n",
    "# values between 0 and 1. The higher the epsilon, the more likely we are to perform a random action\n",
    "# overtime, we want to stop our model to stop exploring\n",
    "epsilon = 0.25\n",
    "\n",
    "# exit, I put the reward for the exit to be the highest one.\n",
    "reward[n-1,n-1] = 2\n",
    "\n",
    "#treasure, I put -1 for the treasure for the ball to pass by the value, but not stay there.\n",
    "reward[2,1] = -1\n",
    "\n",
    "# exit\n",
    "colors[n**2 - 1] = (0,255,0)\n",
    "\n",
    "#treasure\n",
    "colors[n**2 - 7] = (253,255,71)\n",
    "\n",
    "terminals.append(n**2 - 1)\n",
    "\n",
    "\n",
    "\n",
    "actions = {\"up\": 0,\"down\" : 1,\"left\" : 2,\"right\" : 3}\n",
    "\n",
    "\n",
    "\n",
    "# list for accuracies\n",
    "episode_rewards= []\n",
    "\n",
    "\n",
    "\n",
    "while penalities != 0:\n",
    "    i = r(0,n-1)\n",
    "    j = r(0,n-1)\n",
    "    # if the case in the reward array are equal to 0, we replace it by -2\n",
    "    if reward[i,j] == 0 and [i,j] != [0,0] and [i,j] != [n-1,n-1] and [i,j]!=[1,2]:\n",
    "        reward[i,j] = -5\n",
    "        penalities -= 1\n",
    "        colors[n*i+j] = (255,0,0)  #red\n",
    "        terminals.append(n*i+j)\n",
    "\n",
    "# initial q_table\n",
    "Q = np.zeros((n**2,4))\n",
    "states = {}\n",
    "k = 0\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        states[(i,j)] = k\n",
    "        k+=1\n",
    "\n",
    "\n",
    "def layout():\n",
    "    c = 0\n",
    "    for i in range(0,scrx,100):\n",
    "        for j in range(0,scry,100):\n",
    "            pygame.draw.rect(screen,(255,255,255),(j,i,j+100,i+100),0)\n",
    "            pygame.draw.rect(screen,colors[c],(j+3,i+3,j+95,i+95),0)\n",
    "            c+=1\n",
    "\n",
    "\n",
    "def select_action(current_state):\n",
    "    global current_pos,epsilon\n",
    "    possible_actions = []\n",
    "    if np.random.uniform() <= epsilon:\n",
    "        if current_pos[1] != 0:\n",
    "            possible_actions.append(\"left\")\n",
    "        if current_pos[1] != n-1:\n",
    "            possible_actions.append(\"right\")\n",
    "        if current_pos[0] != 0:\n",
    "            possible_actions.append(\"up\")\n",
    "        if current_pos[0] != n-1:\n",
    "            possible_actions.append(\"down\")\n",
    "        action = actions[possible_actions[r(0,len(possible_actions) - 1)]]\n",
    "    else:\n",
    "        m = np.min(Q[current_state])\n",
    "        if current_pos[0] != 0:\n",
    "            possible_actions.append(Q[current_state,0])\n",
    "        else:\n",
    "            possible_actions.append(m - 100)\n",
    "        if current_pos[0] != n-1:\n",
    "            possible_actions.append(Q[current_state,1])\n",
    "        else:\n",
    "            possible_actions.append(m - 100)\n",
    "        if current_pos[1] != 0:\n",
    "            possible_actions.append(Q[current_state,2])\n",
    "        else:\n",
    "            possible_actions.append(m - 100)\n",
    "        if current_pos[1] != n-1:\n",
    "            possible_actions.append(Q[current_state,3])\n",
    "        else:\n",
    "            possible_actions.append(m - 100)\n",
    "        # action = np.argmax(possible_actions)\n",
    "        action = random.choice([i for i,a in enumerate(possible_actions) if a == max(possible_actions)])\n",
    "        return action\n",
    "def episode():\n",
    "    global current_pos,epsilon\n",
    "    current_state = states[(current_pos[0],current_pos[1])]\n",
    "    action = select_action(current_state)\n",
    "    if action == 0:\n",
    "        current_pos[0] -= 1\n",
    "    elif action == 1:\n",
    "        current_pos[0] += 1\n",
    "    elif action == 2:\n",
    "        current_pos[1] -= 1\n",
    "    elif action == 3:\n",
    "        current_pos[1] += 1\n",
    "    new_state = states[(current_pos[0],current_pos[1])]\n",
    "    if new_state not in terminals:\n",
    "        # The core of the algorithm is a Bellman equation \n",
    "        # as a simple value iteration update, using the weighted average of the current value and the new information\n",
    "        Q[current_state,action] += alpha*(reward[current_pos[0],current_pos[1]] + gamma*(np.max(Q[new_state])) - Q[current_state,action])\n",
    "    else:\n",
    "        Q[current_state,action] += alpha*(reward[current_pos[0],current_pos[1]] - Q[current_state,action])\n",
    "        current_pos = [0,0]\n",
    "        epsilon -= 1e-3\n",
    "\n",
    "\n",
    "run = True\n",
    "for i in range(000):\n",
    "    episode()\n",
    "while run:\n",
    "    sleep(0.1)\n",
    "    screen.fill(background)\n",
    "    layout()\n",
    "    pygame.draw.circle(screen,(230,25,129),(current_pos[1]*100 + 50,current_pos[0]*100 + 50),30,0)\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            run = False\n",
    "    pygame.display.flip()\n",
    "    episode()\n",
    "\n",
    "pygame.quit()\n",
    "print(epsilon)\n",
    "# moving_avg = np.convolve(episode_rewards, np.ones((SHOW_EVERY,))/SHOW_EVERY, mode=\"valid\")\n",
    "# plt.plot([i for i in range(len(moving_avg))], moving_avg)\n",
    "# plt.ylabel(f\"reward {SHOW_EVERY} ma\")\n",
    "# plt.xlabel(\"episode #\")\n",
    "# plt.show()\n",
    "\n",
    "# f = open(\"Q.txt\",\"w\")\n",
    "# f.write(pickle.dumps(Q))\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7dfea3c-128a-440d-b6fb-00a20be68c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward[r(0,3),r(0,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcc00692-cd38-411e-9dbe-c563b9067fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., -1.],\n",
       "       [-1.,  0.,  1.,  0.],\n",
       "       [-1., -1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  2.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3eb014ab-3901-41f5-b11b-0c0ed3d4b8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  0.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward[(0,0),(3,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b985763f-1bec-4b2b-a2e7-b23a0a646c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): 0,\n",
       " (0, 1): 1,\n",
       " (0, 2): 2,\n",
       " (0, 3): 3,\n",
       " (1, 0): 4,\n",
       " (1, 1): 5,\n",
       " (1, 2): 6,\n",
       " (1, 3): 7,\n",
       " (2, 0): 8,\n",
       " (2, 1): 9,\n",
       " (2, 2): 10,\n",
       " (2, 3): 11,\n",
       " (3, 0): 12,\n",
       " (3, 1): 13,\n",
       " (3, 2): 14,\n",
       " (3, 3): 15}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states={}\n",
    "k=0\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        states[(i,j)] = k\n",
    "        k+=1\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a80d7c7-d53e-41ac-85a8-9450d520dee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 2.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward = np.zeros((n,n))\n",
    "# exit\n",
    "reward[n-1,n-1] = 2\n",
    "#treasure\n",
    "reward[2,1] = 1\n",
    "\n",
    "while penalities != 0:\n",
    "    i = r(0,n-1)\n",
    "    j = r(0,n-1)\n",
    "    if reward[i,j] == 0 and [i,j] != [0,0] and [i,j] != [n-1,n-1] and [i,j]!=[1,2]:\n",
    "        reward[i,j] = -1\n",
    "        penalities -= 1\n",
    "        colors[n*i+j] = (255,0,0)  #red\n",
    "        terminals.append(n*i+j)\n",
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d964a624-4077-4734-a79d-a6b4d061dbc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
